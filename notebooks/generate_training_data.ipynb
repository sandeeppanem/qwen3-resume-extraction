{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Generate Training Data for Resume Parser Fine-Tuning\n",
        "\n",
        "This notebook generates training data pairs (resume text → structured JSON) for supervised fine-tuning of the Qwen3 resume parser model.\n",
        "\n",
        "**Purpose:**\n",
        "- Processes raw resumes from `combined_resumes.json`\n",
        "- Extracts structured information using LLM to create (input, output) pairs\n",
        "- Generates `extracted_resumes.json` with resume text and structured JSON pairs\n",
        "- Creates the training dataset used for fine-tuning the Qwen3-0.6B model\n",
        "\n",
        "**Workflow:**\n",
        "1. Load raw resumes from `combined_resumes.json`\n",
        "2. For each resume, extract structured JSON using LLM\n",
        "3. Save resume text + extracted JSON pairs to `extracted_resumes.json`\n",
        "4. This data is then converted to Qwen3 chat template format for training\n",
        "\n",
        "**Features:**\n",
        "- Processes resumes one by one with progress tracking\n",
        "- Saves progress after each resume (can resume if interrupted)\n",
        "- Configurable delay between API calls to handle rate limits\n",
        "- Validates JSON output and tracks errors\n",
        "\n",
        "**Note:** This notebook uses placeholders for the LLM API configuration. Replace `YOUR_PROVIDER`, `YOUR_MODEL_NAME`, and the LLM client initialization with your actual API setup.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup and Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import time\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "# TODO: Import your LLM client/API wrapper here\n",
        "# Example: from your_llm_client import YourLLMClient\n",
        "\n",
        "print(\"✓ Imports successful\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# File paths\n",
        "INPUT_FILE = \"combined_resumes.json\"\n",
        "OUTPUT_FILE = \"extracted_resumes.json\"\n",
        "PROGRESS_FILE = \"processing_progress.json\"\n",
        "\n",
        "# API configuration\n",
        "WAIT_TIME_SECONDS = 2\n",
        "PROGRESS_PRINT_INTERVAL = 20  # Print detailed progress every N resumes\n",
        "\n",
        "# TODO: Configure your LLM API settings\n",
        "# Replace these placeholders with your actual API configuration\n",
        "PROVIDER = \"YOUR_PROVIDER\"  # e.g., \"OpenAI\", \"Anthropic\", etc.\n",
        "MODEL = \"YOUR_MODEL_NAME\"   # e.g., \"gpt-4\", \"claude-3\", etc.\n",
        "TEMPERATURE = 0  # Use 0 for deterministic JSON extraction\n",
        "\n",
        "print(f\"Input file: {INPUT_FILE}\")\n",
        "print(f\"Output file: {OUTPUT_FILE}\")\n",
        "print(f\"Wait time between requests: {WAIT_TIME_SECONDS} seconds\")\n",
        "print(f\"Progress update interval: every {PROGRESS_PRINT_INTERVAL} resumes\")\n",
        "print(f\"\\n⚠️  Note: Update PROVIDER and MODEL with your actual API configuration\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prompt Templates\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "SYSTEM_PROMPT = \"\"\"\n",
        "You are an expert resume information extraction system.\n",
        "\n",
        "Your task is to extract a structured professional profile from a resume.\n",
        "\n",
        "STRICT RULES:\n",
        "- Use ONLY information explicitly present in the resume\n",
        "- You MAY summarize or rephrase information that is explicitly stated in the resume, but you MUST NOT add new facts or inferred details.\n",
        "- Do NOT infer or guess missing information\n",
        "- Do NOT fabricate company names, skills, or achievements\n",
        "- If a field is not present or cannot be confidently determined, return null\n",
        "- Normalize job titles and skills where appropriate (e.g., \"SDE\" → \"Software Engineer\")\n",
        "\n",
        "Return ONLY valid JSON.\n",
        "Do NOT include explanations, comments, or markdown.\n",
        "\"\"\"\n",
        "\n",
        "def create_user_prompt(resume_text):\n",
        "    return f\"\"\"\n",
        "Extract a structured professional profile from the resume below.\n",
        "\n",
        "Schema:\n",
        "{{\n",
        "  \"current_title\": string,\n",
        "  \"previous_titles\": string[],\n",
        "  \"current_company\": string,\n",
        "  \"previous_companies\": string[],\n",
        "  \"years_experience\": number,\n",
        "  \"seniority\": \"junior\" | \"mid\" | \"senior\" | \"lead\" | \"principal\",\n",
        "  \"primary_domain\": string,\n",
        "  \"industries\": string[],\n",
        "  \"core_skills\": string[],\n",
        "  \"secondary_skills\": string[],\n",
        "  \"tools\": string[],\n",
        "  \"leadership_experience\": boolean,\n",
        "  \"key_achievements\": string[],\n",
        "  \"location\": string,\n",
        "  \"summary\": string\n",
        "}}\n",
        "\n",
        "Guidelines:\n",
        "- years_experience should be a number (e.g., 7.5)\n",
        "- seniority should reflect the highest demonstrated role\n",
        "- leadership_experience = true only if the resume mentions leading teams, mentoring, managing, or ownership\n",
        "- key_achievements should be impact-oriented (metrics, outcomes, scale)\n",
        "- summary must be a concise professional summary (MAX 300 characters)\n",
        "\n",
        "LIMITING RULES:\n",
        "- For any array field, return AT MOST the 3 most recent or most relevant values.\n",
        "- If more than 3 values exist:\n",
        "  - Job titles and companies: select the 3 most recent based on dates in the resume.\n",
        "  - Skills, tools, industries: select the 3 most prominent based on frequency and emphasis.\n",
        "  - Achievements: select the 3 highest-impact achievements.\n",
        "- Preserve ordering from MOST RECENT or MOST IMPORTANT to LEAST.\n",
        "- If fewer than 3 values exist, return all available.\n",
        "- If no values exist, return null.\n",
        "\n",
        "Resume:\n",
        "<<<BEGIN RESUME>>>\n",
        "{resume_text}\n",
        "<<<END RESUME>>>\n",
        "\"\"\"\n",
        "\n",
        "print(\"✓ Prompts configured\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Helper Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_progress():\n",
        "    \"\"\"Load processing progress from file.\"\"\"\n",
        "    if Path(PROGRESS_FILE).exists():\n",
        "        with open(PROGRESS_FILE, 'r') as f:\n",
        "            return json.load(f)\n",
        "    return {\"last_processed_index\": -1, \"total_processed\": 0}\n",
        "\n",
        "def save_progress(index, total):\n",
        "    \"\"\"Save processing progress to file.\"\"\"\n",
        "    progress = {\n",
        "        \"last_processed_index\": index,\n",
        "        \"total_processed\": total,\n",
        "        \"last_update\": datetime.now().isoformat()\n",
        "    }\n",
        "    with open(PROGRESS_FILE, 'w') as f:\n",
        "        json.dump(progress, f, indent=2)\n",
        "\n",
        "def load_existing_results():\n",
        "    \"\"\"Load existing results from output file.\"\"\"\n",
        "    if Path(OUTPUT_FILE).exists():\n",
        "        with open(OUTPUT_FILE, 'r') as f:\n",
        "            return json.load(f)\n",
        "    return []\n",
        "\n",
        "def save_result(results):\n",
        "    \"\"\"Save results to output file.\"\"\"\n",
        "    with open(OUTPUT_FILE, 'w') as f:\n",
        "        json.dump(results, f, indent=2)\n",
        "\n",
        "def extract_resume_info(resume_text, llm_client):\n",
        "    \"\"\"Extract structured information from a resume using LLM.\"\"\"\n",
        "    user_prompt = create_user_prompt(resume_text)\n",
        "    final_prompt = f\"\"\"SYSTEM:\n",
        "{SYSTEM_PROMPT}\n",
        "\n",
        "USER:\n",
        "{user_prompt}\n",
        "\"\"\"\n",
        "    \n",
        "    try:\n",
        "        # TODO: Replace this with your actual LLM API call\n",
        "        # The structure should:\n",
        "        # 1. Send the prompt to your LLM API\n",
        "        # 2. Receive the response text\n",
        "        # 3. Return the extracted text\n",
        "        \n",
        "        # Example structure (adapt to your API):\n",
        "        # response = llm_client.generate(\n",
        "        #     prompt=final_prompt,\n",
        "        #     model=MODEL,\n",
        "        #     temperature=TEMPERATURE\n",
        "        # )\n",
        "        # extracted_text = response[\"text\"]  # or response.text, depending on your API\n",
        "        \n",
        "        # Placeholder - replace with actual API call\n",
        "        response = llm_client.generate(\n",
        "            prompt=final_prompt,\n",
        "            model=MODEL,\n",
        "            temperature=TEMPERATURE\n",
        "        )\n",
        "        extracted_text = response[\"text\"]  # Adjust based on your API response structure\n",
        "        \n",
        "        # Try to parse as JSON to validate\n",
        "        try:\n",
        "            extracted_json = json.loads(extracted_text)\n",
        "            return extracted_json, None\n",
        "        except json.JSONDecodeError as e:\n",
        "            return extracted_text, f\"JSON parsing error: {str(e)}\"\n",
        "            \n",
        "    except Exception as e:\n",
        "        return None, f\"API error: {str(e)}\"\n",
        "\n",
        "print(\"✓ Helper functions defined\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Input Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load combined resumes\n",
        "print(f\"Loading resumes from {INPUT_FILE}...\")\n",
        "with open(INPUT_FILE, 'r') as f:\n",
        "    resumes = json.load(f)\n",
        "\n",
        "total_resumes = len(resumes)\n",
        "print(f\"✓ Loaded {total_resumes} resumes\")\n",
        "\n",
        "# Load progress\n",
        "progress = load_progress()\n",
        "start_index = progress[\"last_processed_index\"] + 1\n",
        "\n",
        "if start_index > 0:\n",
        "    print(f\"\\n⚠️  Resuming from index {start_index}\")\n",
        "    print(f\"   Already processed: {progress['total_processed']} resumes\")\n",
        "else:\n",
        "    print(f\"\\n▶️  Starting fresh processing\")\n",
        "\n",
        "remaining = total_resumes - start_index\n",
        "print(f\"   Remaining to process: {remaining} resumes\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Process Resumes\n",
        "\n",
        "**Main Processing Loop** - This cell will process all remaining resumes with rate limiting and progress tracking.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Initialize your LLM client\n",
        "# Replace this with your actual LLM client initialization\n",
        "# Example: llm_client = YourLLMClient(api_key=\"your_key\")\n",
        "llm_client = None  # Placeholder - initialize your LLM client here\n",
        "print(\"✓ LLM client initialized\\n\")\n",
        "\n",
        "# Load existing results\n",
        "results = load_existing_results()\n",
        "print(f\"Loaded {len(results)} existing results\\n\")\n",
        "\n",
        "# Process resumes\n",
        "print(\"=\"*70)\n",
        "print(\"STARTING PROCESSING\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "successful_count = 0\n",
        "error_count = 0\n",
        "start_time = time.time()\n",
        "\n",
        "for i in range(start_index, total_resumes):\n",
        "    resume_data = resumes[i]\n",
        "    resume_text = resume_data.get(\"resume_text\", \"\")\n",
        "    \n",
        "    # Determine if we should print progress for this resume\n",
        "    should_print = ((i - start_index + 1) % PROGRESS_PRINT_INTERVAL == 0) or (i == start_index) or (i == total_resumes - 1)\n",
        "    \n",
        "    if should_print:\n",
        "        print(f\"\\n[{i+1}/{total_resumes}] Processing resume...\")\n",
        "    \n",
        "    if not resume_text or resume_text.strip() == \"\":\n",
        "        if should_print:\n",
        "            print(\"  ⚠️  Empty resume text, skipping\")\n",
        "        results.append({\n",
        "            \"index\": i,\n",
        "            \"resume_text\": resume_text,\n",
        "            \"extracted_json\": None,\n",
        "            \"error\": \"Empty resume text\",\n",
        "            \"processed_at\": datetime.now().isoformat()\n",
        "        })\n",
        "        error_count += 1\n",
        "        continue\n",
        "    \n",
        "    # Extract information\n",
        "    extracted_json, error = extract_resume_info(resume_text, llm_client)\n",
        "    \n",
        "    # Prepare result\n",
        "    result = {\n",
        "        \"index\": i,\n",
        "        \"resume_text\": resume_text,\n",
        "        \"extracted_json\": extracted_json,\n",
        "        \"error\": error,\n",
        "        \"processed_at\": datetime.now().isoformat()\n",
        "    }\n",
        "    \n",
        "    results.append(result)\n",
        "    \n",
        "    # Update counters\n",
        "    if error:\n",
        "        error_count += 1\n",
        "        if should_print:\n",
        "            print(f\"  ❌ Error: {error}\")\n",
        "    else:\n",
        "        successful_count += 1\n",
        "        if should_print:\n",
        "            print(f\"  ✓ Successfully extracted\")\n",
        "    \n",
        "    # Save progress after each resume\n",
        "    save_result(results)\n",
        "    save_progress(i, len(results))\n",
        "    \n",
        "    # Progress summary - only print every N resumes\n",
        "    if should_print:\n",
        "        elapsed = time.time() - start_time\n",
        "        avg_time = elapsed / (i - start_index + 1)\n",
        "        remaining_count = total_resumes - i - 1\n",
        "        eta_seconds = avg_time * remaining_count\n",
        "        eta_minutes = eta_seconds / 60\n",
        "        \n",
        "        print(f\"  Progress: {len(results)}/{total_resumes} | Success: {successful_count} | Errors: {error_count}\")\n",
        "        print(f\"  Avg time: {avg_time:.2f}s | ETA: {eta_minutes:.1f} minutes\")\n",
        "    \n",
        "    # Wait before next request (except for the last one)\n",
        "    if i < total_resumes - 1:\n",
        "        time.sleep(WAIT_TIME_SECONDS)\n",
        "\n",
        "# Final summary\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"PROCESSING COMPLETE\")\n",
        "print(\"=\"*70)\n",
        "print(f\"\\nTotal processed: {len(results)}\")\n",
        "print(f\"Successful: {successful_count}\")\n",
        "print(f\"Errors: {error_count}\")\n",
        "print(f\"\\nResults saved to: {OUTPUT_FILE}\")\n",
        "print(f\"Total time: {(time.time() - start_time)/60:.1f} minutes\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## View Sample Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load and display first few successful results\n",
        "with open(OUTPUT_FILE, 'r') as f:\n",
        "    all_results = json.load(f)\n",
        "\n",
        "# Find first successful result\n",
        "successful_results = [r for r in all_results if r['error'] is None]\n",
        "\n",
        "if successful_results:\n",
        "    print(f\"Showing first successful result (out of {len(successful_results)} total):\")\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    \n",
        "    sample = successful_results[0]\n",
        "    print(f\"Resume Index: {sample['index']}\")\n",
        "    print(f\"Processed At: {sample['processed_at']}\")\n",
        "    print(\"\\nExtracted JSON:\")\n",
        "    print(json.dumps(sample['extracted_json'], indent=2))\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(f\"\\nResume Text (first 500 chars):\")\n",
        "    print(sample['resume_text'][:500] + \"...\")\n",
        "else:\n",
        "    print(\"No successful results found yet.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Statistics and Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze results\n",
        "with open(OUTPUT_FILE, 'r') as f:\n",
        "    all_results = json.load(f)\n",
        "\n",
        "total = len(all_results)\n",
        "successful = sum(1 for r in all_results if r['error'] is None)\n",
        "failed = total - successful\n",
        "\n",
        "print(\"PROCESSING STATISTICS\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Total processed: {total}\")\n",
        "print(f\"Successful: {successful} ({successful/total*100:.1f}%)\")\n",
        "print(f\"Failed: {failed} ({failed/total*100:.1f}%)\")\n",
        "\n",
        "if failed > 0:\n",
        "    print(\"\\nError Summary:\")\n",
        "    errors = {}\n",
        "    for r in all_results:\n",
        "        if r['error']:\n",
        "            error_type = r['error'].split(':')[0]\n",
        "            errors[error_type] = errors.get(error_type, 0) + 1\n",
        "    \n",
        "    for error_type, count in sorted(errors.items(), key=lambda x: x[1], reverse=True):\n",
        "        print(f\"  - {error_type}: {count}\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
