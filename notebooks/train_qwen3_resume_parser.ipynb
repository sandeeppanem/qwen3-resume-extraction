{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8kYoBjMQJFAW"
   },
   "source": [
    "# Qwen3 Resume Parser Fine-Tuning with LoRA\n",
    "\n",
    "This notebook fine-tunes Qwen3-0.6B base model for resume parsing using LoRA (Low-Rank Adaptation) for efficient fine-tuning.\n",
    "\n",
    "**Features:**\n",
    "- LoRA fine-tuning for memory efficiency\n",
    "- Supervised Fine-Tuning (SFT) using TRL's SFTTrainer\n",
    "- Optimized hyperparameters for ~5k samples\n",
    "- Google Colab GPU support\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OGA9i1BvJFAY"
   },
   "source": [
    "## 1. Environment Setup and GPU Check\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_78BhQWtJFAY",
    "outputId": "74377087-1021-40e2-cc2e-64218d6ad330"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ GPU available: NVIDIA L4\n",
      "✓ CUDA version: 12.6\n",
      "✓ GPU memory: 22.16 GB\n"
     ]
    }
   ],
   "source": [
    "# Check GPU availability\n",
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"✓ GPU available: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"✓ CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"✓ GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
    "else:\n",
    "    print(\"⚠️  No GPU detected. Training will be slow on CPU.\")\n",
    "    print(\"   Please enable GPU in Colab: Runtime → Change runtime type → GPU\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BxnxgRuRJFAa",
    "outputId": "95da6a73-4e2b-478e-f1fc-e5183cd324c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m518.9/518.9 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.1/59.1 MB\u001b[0m \u001b[31m39.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h✓ Packages installed successfully\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "!pip install -q transformers peft trl datasets accelerate bitsandbytes\n",
    "\n",
    "print(\"✓ Packages installed successfully\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K1P_CJ4IJFAa"
   },
   "source": [
    "## 2. Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3lZ5Q_TPJFAa",
    "outputId": "4bb7101c-412e-4dab-a5de-fc579ef3c6f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Imports successful\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from peft import LoraConfig, get_peft_model, TaskType, PeftModel\n",
    "from trl import SFTTrainer, SFTConfig\n",
    "from datasets import load_dataset\n",
    "import os\n",
    "\n",
    "print(\"✓ Imports successful\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S_OqlCTZJFAa"
   },
   "source": [
    "## 3. Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YTLPM4YmJFAb",
    "outputId": "fddd5afd-2806-4f2e-f991-a8459cbb0f0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Qwen/Qwen3-0.6B\n",
      "Dataset: /home/qwen3_training_dataset.jsonl\n",
      "Output directory: /home/qwen3-resume-parser-lora\n"
     ]
    }
   ],
   "source": [
    "# Model configuration\n",
    "MODEL_NAME = \"Qwen/Qwen3-0.6B\"\n",
    "\n",
    "# Dataset configuration\n",
    "DATASET_PATH = \"/home/qwen3_training_dataset.jsonl\"  # Path to your converted dataset\n",
    "# If uploading to Colab, upload the JSONL file and update the path\n",
    "\n",
    "# Output configuration\n",
    "OUTPUT_DIR = \"/home/qwen3-resume-parser-lora\"\n",
    "FINAL_MODEL_DIR = \"/home/qwen3-resume-parser-lora-final\"\n",
    "\n",
    "print(f\"Model: {MODEL_NAME}\")\n",
    "print(f\"Dataset: {DATASET_PATH}\")\n",
    "print(f\"Output directory: {OUTPUT_DIR}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VriKOlhhJFAb"
   },
   "source": [
    "## 4. Load Model and Tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 504,
     "referenced_widgets": [
      "30ecca361e924da688200f3e034e4cf3",
      "422c9670acad4721a9afb5e1de93aec8",
      "613711a3fdfd400db2f9529cec194d97",
      "77f6b3a20cb440ffa10a8f1d3d98c125",
      "694e1f04aadf404a963ff79685097f7a",
      "8594e343780c4ea3b43f661473eb1118",
      "691b74d8b8064c7fbdfb90a54c5b1245",
      "faa2fa650f82430a86c1ebacda8926b5",
      "31f3f7bd25c7424f9378eb02e6ff2b6a",
      "c035a1063dec436e83267c79bfbd98f4",
      "48ee75cb104e4a79bb4beab92f5c4dda",
      "de3cf5766d044a5e80525c85b3582ec6",
      "edb13e8a8e4349f79aa8e7696ee3bb1c",
      "c223316fe1ed463e88038c9e1b203d51",
      "ac8ed3ca0f9f4384885717cfd738254a",
      "843ea069b0464c578bb6068b5836ef25",
      "ecb02aa077b94015bd7f3ad29e43e308",
      "71fec51182104bc1a777c7b1c3e2d76e",
      "c86f266add24476dbe55fc9c9c949e5f",
      "4fa8b2d823c74707ba91b8899f014f04",
      "027fc1f429374bfd819a6d78518ba418",
      "73e85b2cfb9a4f64b05cdae30a7b67d3",
      "a645bca7d0894009a207f497e5d5063d",
      "e413f5b9d8e2467094fbc1f2d799f798",
      "31903c6eccae4c04a2775b86a315cb42",
      "f6caa980702a43bd8ca489c8d7cfb469",
      "ef8bcf2004b64946aa6f568d1401fdf6",
      "20350ec4fd3c47a0a93a106ecfa5e23e",
      "3949e293c84c4826a0a7200c51bc7d48",
      "e398a6160f8a47b489def2a124cecb8b",
      "96637bccc79e47199e93965ba14e71e2",
      "46fe07bb78364396acf93fbda3e7ce57",
      "36bcae696123491580e63e5df8637068",
      "223faf093f8745ec9aa7beed0a8629b6",
      "1891881b058743dbbfcd407642b0d232",
      "60dd725186164f139035a2f4e125e6ba",
      "93f94b3b86ef4542b1d503c61292c5ec",
      "1dd3a66eeba943d1984e9e7d18909fb8",
      "f0ff9eb96b3847fd9d6caad9675103fa",
      "9ef49247d9944ef88f87ee567646c430",
      "5ced6627d9854331b66c0304c74819a8",
      "d25870a2525049c8a89fa1670a45c407",
      "cb1226b03a974a3a8741a17a14783952",
      "618a310098ef47d0ad708a1e81c1c1ae",
      "9979ab37c9244d2a9aa01d44b1475490",
      "cb1fbad06ff5490e9ed0408ebb0f35c4",
      "4c62feb1416f49b4b2fc2596f32dccd2",
      "be17159af5824014a89d09e567eba995",
      "8fc224306a8d4387b53a8b6bc99ab783",
      "c97b91a22af74a40abae8d3b6050452d",
      "df461b90e1a04ba69f7870adc0188ac4",
      "799a042ee75647e0925a23377cd0cec1",
      "84f002a01c614791a374099289a91992",
      "76d27004a12244fbb0ee9cb3b0c16cac",
      "9786a2b827814749a23761f291cd5c03",
      "7b87b3acc1c44d179d964210ec27e171",
      "a5c9c37955564f2a99f82091236e02b0",
      "5618875510e74d73b02c9aaf47bec72c",
      "d3868046e5b74aacba79503f3da70c2e",
      "4533edf52f064053aa33f19957b4d5b1",
      "b82165ac20ac46e28928961cf53ffdc0",
      "f66e83861af34f53afb748ddcb56e1a3",
      "2f75af7ac5c445dd95fed3390eab835e",
      "0bc7a9e57c02471fac25d2a1180c6240",
      "8d47bdc757a84403b1214ce0501c5bdd",
      "938072aad14942ebb7980f2eafe78c2d",
      "092b888959f44a3e840137043ba0829a",
      "e428c15ec8064d0da52f3e60d8798fc9",
      "0115b4f600d84a698e649845062212c0",
      "57d5c046d1494ed8b1003d16c110cd79",
      "f49728ff700e4366bfb2506da64d8e00",
      "0f2724281e4b419bbac6327236cb761f",
      "058830d4acf74bbb97352665dd82fb14",
      "ac8db64054a14f62a8a53e33b8b5edb0",
      "dc59db76d0144ce2bf5a95d3b8863e80",
      "cea6d208ad6a4d588dd3b20c5a0e0f22",
      "c5bd6f4c03344398a5c0943da4e8a31e"
     ]
    },
    "id": "kezhkEXaJFAb",
    "outputId": "726b7afb-cafe-48ec-d2a6-aed5e0031bab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30ecca361e924da688200f3e034e4cf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de3cf5766d044a5e80525c85b3582ec6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a645bca7d0894009a207f497e5d5063d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "223faf093f8745ec9aa7beed0a8629b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Tokenizer loaded\n",
      "\n",
      "Loading model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9979ab37c9244d2a9aa01d44b1475490",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/726 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b87b3acc1c44d179d964210ec27e171",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.50G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "092b888959f44a3e840137043ba0829a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Model loaded\n",
      "Model device: cuda:0\n",
      "Model dtype: torch.float16\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading tokenizer...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, trust_remote_code=True)\n",
    "\n",
    "# Set padding token if not present\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "print(\"✓ Tokenizer loaded\")\n",
    "\n",
    "print(\"\\nLoading model...\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    torch_dtype=torch.float16,  # Use float16 for memory efficiency\n",
    "    device_map=\"auto\",  # Automatically handle device placement\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "print(\"✓ Model loaded\")\n",
    "print(f\"Model device: {next(model.parameters()).device}\")\n",
    "print(f\"Model dtype: {next(model.parameters()).dtype}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bKOme7d9JFAc"
   },
   "source": [
    "## 5. Configure LoRA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mkM4HD_5JFAc",
    "outputId": "de93a552-6f8e-4051-9ae8-01253cd3a72a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying LoRA configuration...\n",
      "trainable params: 2,293,760 || all params: 598,343,680 || trainable%: 0.3834\n",
      "\n",
      "✓ LoRA configuration applied\n"
     ]
    }
   ],
   "source": [
    "# LoRA configuration following best practices\n",
    "lora_config = LoraConfig(\n",
    "    r=8,  # Rank - controls adapter capacity\n",
    "    lora_alpha=16,  # Scaling factor (typically 2x rank)\n",
    "    target_modules=[\"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\"],  # Qwen3 attention modules\n",
    "    lora_dropout=0.05,  # Dropout for regularization\n",
    "    bias=\"none\",  # Don't train bias terms\n",
    "    task_type=TaskType.CAUSAL_LM\n",
    ")\n",
    "\n",
    "# Apply LoRA to model\n",
    "print(\"Applying LoRA configuration...\")\n",
    "model = get_peft_model(model, lora_config)\n",
    "\n",
    "# Print trainable parameters\n",
    "model.print_trainable_parameters()\n",
    "print(\"\\n✓ LoRA configuration applied\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IV3nl5exJFAc"
   },
   "source": [
    "## 6. Load Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312,
     "referenced_widgets": [
      "b8a34dd606384cdbb9f660dcf05c9311",
      "7f6521ab7e1746d795fe437a1bf25ab4",
      "90c7032b73364741a30044abc2e3a5d4",
      "fe15e0a0a34945cfa84b963093a4a75a",
      "0a2a2e0bf34041edb50f35796d786828",
      "3d6f77cc7530447a89642aeacdc52f5b",
      "7c98abe8953c4c42aa15dc345390b47a",
      "a8be2d8c18fc4de19667fff3d3a07923",
      "7fb84b930a8e4c5699160b1934cea6f8",
      "b22496b483ee48379a1bc8fe9e473dca",
      "a5a7f8b62ac6455e96c2f55002058345"
     ]
    },
    "id": "GvxchxD_JFAc",
    "outputId": "6f31c618-77ca-4a44-f063-cbf7b5a7ee2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset from /home/qwen3_training_dataset.jsonl...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8a34dd606384cdbb9f660dcf05c9311",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Dataset loaded\n",
      "  Train examples: 4879\n",
      "  Sample keys: ['text']\n",
      "\n",
      "  Sample text (first 500 chars):\n",
      "  <|im_start|>system\n",
      "You are an expert resume parser. Extract structured information from resumes and return ONLY valid JSON. Do not include explanations or extra text.<|im_end|>\n",
      "<|im_start|>user\n",
      "Resume:\n",
      "ADULT EDUCATION INSTRUCTOR\n",
      "Summary\n",
      "Seasoned Agriculture Teacher with more than 20 years of experience in this world of education. Excellent teaching and leadership skills. Track\n",
      "record of achieving exceptional results in not only FFA programs but also Credit Recovery Programs at my current high sc...\n"
     ]
    }
   ],
   "source": [
    "print(f\"Loading dataset from {DATASET_PATH}...\")\n",
    "\n",
    "# Load JSONL dataset\n",
    "dataset = load_dataset(\"json\", data_files=DATASET_PATH)\n",
    "\n",
    "# The dataset already has \"text\" field from conversion script\n",
    "# No additional preprocessing needed\n",
    "\n",
    "print(f\"✓ Dataset loaded\")\n",
    "print(f\"  Train examples: {len(dataset['train'])}\")\n",
    "print(f\"  Sample keys: {list(dataset['train'][0].keys())}\")\n",
    "\n",
    "# Show a sample (first 500 chars)\n",
    "if len(dataset['train']) > 0:\n",
    "    sample_text = dataset['train'][0]['text']\n",
    "    print(f\"\\n  Sample text (first 500 chars):\")\n",
    "    print(f\"  {sample_text[:500]}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vKzRWtiBP2KZ",
    "outputId": "4f528dfa-18f7-4c25-db56-b4e0d78c3b69"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU cache cleared\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "print(\"GPU cache cleared\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gqA5P2otJFAc"
   },
   "source": [
    "## 7. Configure Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ku5R7TOHJFAd",
    "outputId": "6935ea59-0652-4aa1-c0b6-2fbe79f2ad87"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Configuration:\n",
      "  Batch size: 2\n",
      "  Gradient accumulation: 8\n",
      "  Effective batch size: 16\n",
      "  Learning rate: 0.0001\n",
      "  Epochs: 3\n",
      "  Max sequence length: 1536\n",
      "  Warmup steps: 100\n",
      "  Estimated total steps: ~912\n",
      "\n",
      "✓ Training configuration created\n"
     ]
    }
   ],
   "source": [
    "# Training hyperparameters optimized for ~5k samples\n",
    "# Based on Hugging Face SmolLM3 SFT guide\n",
    "\n",
    "BATCH_SIZE =2  # Reduced batch size\n",
    "GRADIENT_ACCUMULATION_STEPS = 8  # Increased to maintain effective batch size\n",
    "LEARNING_RATE = 1e-4\n",
    "NUM_EPOCHS = 3\n",
    "MAX_SEQ_LENGTH = 1536\n",
    "WARMUP_STEPS = 100\n",
    "\n",
    "# Calculate total steps\n",
    "total_steps = (len(dataset['train']) // (BATCH_SIZE * GRADIENT_ACCUMULATION_STEPS)) * NUM_EPOCHS\n",
    "\n",
    "print(\"Training Configuration:\")\n",
    "print(f\"  Batch size: {BATCH_SIZE}\")\n",
    "print(f\"  Gradient accumulation: {GRADIENT_ACCUMULATION_STEPS}\")\n",
    "print(f\"  Effective batch size: {BATCH_SIZE * GRADIENT_ACCUMULATION_STEPS}\")\n",
    "print(f\"  Learning rate: {LEARNING_RATE}\")\n",
    "print(f\"  Epochs: {NUM_EPOCHS}\")\n",
    "print(f\"  Max sequence length: {MAX_SEQ_LENGTH}\")\n",
    "print(f\"  Warmup steps: {WARMUP_STEPS}\")\n",
    "print(f\"  Estimated total steps: ~{total_steps}\")\n",
    "\n",
    "# Configure training arguments\n",
    "# In newer TRL versions, use max_length instead of max_seq_length\n",
    "training_args = SFTConfig(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    gradient_accumulation_steps=GRADIENT_ACCUMULATION_STEPS,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    num_train_epochs=NUM_EPOCHS,\n",
    "    warmup_steps=WARMUP_STEPS,\n",
    "    logging_steps=50,\n",
    "    save_steps=500,\n",
    "    save_total_limit=3,\n",
    "    fp16=True,  # Mixed precision training for memory efficiency\n",
    "    optim=\"adamw_torch\",\n",
    "    weight_decay=0.01,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    report_to=\"none\",  # Set to \"wandb\" or \"tensorboard\" if you want logging\n",
    "    push_to_hub=False,  # Set to True if pushing to HuggingFace Hub\n",
    "    remove_unused_columns=False,\n",
    "    gradient_checkpointing=True, # Enable gradient checkpointing for memory efficiency\n",
    "    # SFT-specific parameters\n",
    "    dataset_text_field=\"text\",  # Field containing the formatted text\n",
    "    max_length=MAX_SEQ_LENGTH,  # Use max_length instead of max_seq_length\n",
    "    packing=False,  # Don't pack sequences - each example is separate\n",
    ")\n",
    "\n",
    "print(\"\\n✓ Training configuration created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ixjaGJ6UJFAd"
   },
   "source": [
    "## 8. Initialize Trainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202,
     "referenced_widgets": [
      "c64ce4f3280f4781b08c88c29f98c565",
      "68d17198b44148b9b82d803b8ef7b64e",
      "a7bbf44974f94982a600d66a3c5d3436",
      "f66bdbc1303b4546afb0d57abba5903b",
      "2ec3228ea4e143f6b5ff5e6ab63bf833",
      "d1d9340d6d2b4778b76d2aa58fceeeec",
      "a3909aa812094203a181c6f9e440576f",
      "b09746094e404c258c5a2584b30d2daf",
      "8960f82400b94d7e928e9bdabab8c689",
      "f44ffafa15324ab79999a9f8d746b0d0",
      "f5324c72804a4dcc910d71fb42163fea",
      "a2023a692fa84250ad0b53b6554d4d6b",
      "9e3a1b61d47245199c3ccde4d8d3ffaf",
      "9a1d01ea39124c5799a1bb8f78a91b0e",
      "896b969b05394e1f8bb59acf106e59f0",
      "7206a7fce2904498bf250f5e265bdf8c",
      "ca683cb2b8564712929b25e6cdb0e729",
      "bd10a4f0ea2341fdb23b35fad4ccca0a",
      "fdd350c4ac4849949f9c70d9f5a46ec8",
      "ff5eb11233b64836b79adfc44db0dcf1",
      "2575b6af5b6c45af9a3f528256ef6bb0",
      "25aa138d246d46618e37062698719acf",
      "2a80bb4d5b2f4d19ac7fa16da0ea4983",
      "7d24063fde1e44df9586d2a9ab6e4c19",
      "6d3832f6c3de42029647b732c87f96a7",
      "4b5bffb95c984d3dbd2563899afcf2f1",
      "c376acefd0c74665adc3fcc11c30f6d4",
      "6219e9032c3e41439040d4ce6ec5e678",
      "a64ba7c2e5c6436abd4b7aa608c54750",
      "854e9eea47264bf192e5c78d19333675",
      "e16626541f214aadbd2092e2d6ed3c49",
      "61adc8d505da48589374c25ead0d0660",
      "54f1f17fdbbe47c9b459622f2d42525a"
     ]
    },
    "id": "jovrbE2kJFAd",
    "outputId": "cd70da9c-6bd6-4067-833c-b709d64593e4"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c64ce4f3280f4781b08c88c29f98c565",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding EOS to train dataset:   0%|          | 0/4879 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2023a692fa84250ad0b53b6554d4d6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing train dataset:   0%|          | 0/4879 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a80bb4d5b2f4d19ac7fa16da0ea4983",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Truncating train dataset:   0%|          | 0/4879 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model is already on multiple devices. Skipping the move to device specified in `args`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Trainer initialized\n",
      "  Training examples: 4879\n",
      "  Output directory: /home/qwen3-resume-parser-lora\n"
     ]
    }
   ],
   "source": [
    "# Initialize SFTTrainer\n",
    "# In newer TRL versions, dataset_text_field, max_seq_length, and packing are in SFTConfig\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    args=training_args,\n",
    ")\n",
    "\n",
    "print(\"✓ Trainer initialized\")\n",
    "print(f\"  Training examples: {len(dataset['train'])}\")\n",
    "print(f\"  Output directory: {OUTPUT_DIR}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ezkTP48JFAd"
   },
   "source": [
    "## 9. Start Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 747
    },
    "id": "32GBwT_SJFAe",
    "outputId": "918e34c9-bc05-421b-ce89-15707e38b9be"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None, 'pad_token_id': 151643}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='915' max='915' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [915/915 1:47:36, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>3.090200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.726200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>2.601500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>2.569000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>2.536200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>2.514500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>2.499400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>2.471500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>2.478000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.479000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>2.439800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>2.456100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>2.432400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>2.468300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>2.444900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>2.417100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>2.442900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>2.401400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "✓ Training completed!\n"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "print(\"Starting training...\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"✓ Training completed!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vhNBBDITJFAe"
   },
   "source": [
    "## 10. Save Final Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JWc0s9w_JFAe",
    "outputId": "7ea92882-4e74-4733-f4bd-dded2ac42377"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving final model to /home/qwen3-resume-parser-lora-final...\n",
      "✓ Model saved to /home/qwen3-resume-parser-lora-final\n",
      "\n",
      "To download the model from Colab:\n",
      "  - Use Files panel on the left\n",
      "  - Or run: !zip -r /home/qwen3-resume-parser-lora-final.zip /home/qwen3-resume-parser-lora-final\n"
     ]
    }
   ],
   "source": [
    "# Save final model\n",
    "print(f\"Saving final model to {FINAL_MODEL_DIR}...\")\n",
    "\n",
    "trainer.save_model(FINAL_MODEL_DIR)\n",
    "tokenizer.save_pretrained(FINAL_MODEL_DIR)\n",
    "\n",
    "print(f\"✓ Model saved to {FINAL_MODEL_DIR}\")\n",
    "print(\"\\nTo download the model from Colab:\")\n",
    "print(f\"  - Use Files panel on the left\")\n",
    "print(f\"  - Or run: !zip -r {FINAL_MODEL_DIR}.zip {FINAL_MODEL_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bbU9DInuKLzC",
    "outputId": "521b0ed4-2727-4155-e7c5-b068c254120d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: home/qwen3-resume-parser-lora-final/ (stored 0%)\n",
      "  adding: home/qwen3-resume-parser-lora-final/README.md (deflated 65%)\n",
      "  adding: home/qwen3-resume-parser-lora-final/chat_template.jinja (deflated 76%)\n",
      "  adding: home/qwen3-resume-parser-lora-final/tokenizer_config.json (deflated 90%)\n",
      "  adding: home/qwen3-resume-parser-lora-final/special_tokens_map.json (deflated 69%)\n",
      "  adding: home/qwen3-resume-parser-lora-final/training_args.bin (deflated 53%)\n",
      "  adding: home/qwen3-resume-parser-lora-final/adapter_model.safetensors (deflated 7%)\n",
      "  adding: home/qwen3-resume-parser-lora-final/added_tokens.json (deflated 68%)\n",
      "  adding: home/qwen3-resume-parser-lora-final/tokenizer.json (deflated 81%)\n",
      "  adding: home/qwen3-resume-parser-lora-final/adapter_config.json (deflated 58%)\n",
      "  adding: home/qwen3-resume-parser-lora-final/vocab.json (deflated 61%)\n",
      "  adding: home/qwen3-resume-parser-lora-final/merges.txt (deflated 57%)\n"
     ]
    }
   ],
   "source": [
    "!zip -r /home/qwen3-resume-parser-lora-final.zip /home/qwen3-resume-parser-lora-final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GYDxGuI0JFAe"
   },
   "source": [
    "## 11. Inference Example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e9NPcxN1Mlj0",
    "outputId": "f0600e35-3549-41ce-fdf0-a2e4242c0909"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading fine-tuned model for inference...\n",
      "✓ Fine-tuned model loaded\n",
      "\n",
      "GENERATED RESPONSE:\n",
      " {\"current_title\": \"Senior IT Project Manager/Consultant\", \"previous_titles\": [\"Senior IT Project Manager/Consultant\", \"Senior IT Project Manager/Consultant\"], \"current_company\": \"Northern Trust Bank\", \"previous_companies\": [\"Northern Trust Bank\", \"Northern Trust Bank\"], \"years_experience\": 20, \"seniority\": \"senior\", \"primary_domain\": \"IT Project Management\", \"industries\": [\"Banking\", \"IT Infrastructure\", \"IT Consulting\"], \"core_skills\": [\"Project Management\", \"ITIL\", \"Project Management Professional (PMP)\"], \"secondary_skills\": [\"Process Design\", \"Risk Management\", \"Team Building\"], \"tools\": [\"MS Office Suite\", \"MS Project\", \"SharePoint\"], \"leadership_experience\": true, \"key_achievements\": [\"Managed multiple medium-sized IDM/IAM projects from Initiation through Design, including Program Management\", \"Led a multi-year, multi-phased, large SDLC Project (IDM Rel 1.6 Web Cash Movement) and managed many small SDLC projects\", \"Managed a project that reduced costs, increased revenue and improved efficiency through the intelligent application of technology\"], \"location\": \"Chicago, IL\", \"summary\": \"Senior IT Project Manager/Consultant with 20+ years' experience in project management, ITIL, and large-scale IDM/IAM projects; proven ability to manage multiple projects, reduce costs, and deliver business value.\"}\n",
      "\n",
      "✓ Valid JSON\n",
      "{\n",
      "  \"current_title\": \"Senior IT Project Manager/Consultant\",\n",
      "  \"previous_titles\": [\n",
      "    \"Senior IT Project Manager/Consultant\",\n",
      "    \"Senior IT Project Manager/Consultant\"\n",
      "  ],\n",
      "  \"current_company\": \"Northern Trust Bank\",\n",
      "  \"previous_companies\": [\n",
      "    \"Northern Trust Bank\",\n",
      "    \"Northern Trust Bank\"\n",
      "  ],\n",
      "  \"years_experience\": 20,\n",
      "  \"seniority\": \"senior\",\n",
      "  \"primary_domain\": \"IT Project Management\",\n",
      "  \"industries\": [\n",
      "    \"Banking\",\n",
      "    \"IT Infrastructure\",\n",
      "    \"IT Consulting\"\n",
      "  ],\n",
      "  \"core_skills\": [\n",
      "    \"Project Management\",\n",
      "    \"ITIL\",\n",
      "    \"Project Management Professional (PMP)\"\n",
      "  ],\n",
      "  \"secondary_skills\": [\n",
      "    \"Process Design\",\n",
      "    \"Risk Management\",\n",
      "    \"Team Building\"\n",
      "  ],\n",
      "  \"tools\": [\n",
      "    \"MS Office Suite\",\n",
      "    \"MS Project\",\n",
      "    \"SharePoint\"\n",
      "  ],\n",
      "  \"leadership_experience\": true,\n",
      "  \"key_achievements\": [\n",
      "    \"Managed multiple medium-sized IDM/IAM projects from Initiation through Design, including Program Management\",\n",
      "    \"Led a multi-year, multi-phased, large SDLC Project (IDM Rel 1.6 Web Cash Movement) and managed many small SDLC projects\",\n",
      "    \"Managed a project that reduced costs, increased revenue and improved efficiency through the intelligent application of technology\"\n",
      "  ],\n",
      "  \"location\": \"Chicago, IL\",\n",
      "  \"summary\": \"Senior IT Project Manager/Consultant with 20+ years' experience in project management, ITIL, and large-scale IDM/IAM projects; proven ability to manage multiple projects, reduce costs, and deliver business value.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import PeftModel\n",
    "import torch\n",
    "import json\n",
    "\n",
    "print(\"Loading fine-tuned model for inference...\")\n",
    "\n",
    "# Load base model\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "# Load LoRA adapter\n",
    "model = PeftModel.from_pretrained(base_model, FINAL_MODEL_DIR)\n",
    "model.eval()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(FINAL_MODEL_DIR, trust_remote_code=True)\n",
    "\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "print(\"✓ Fine-tuned model loaded\")\n",
    "\n",
    "example_resume = \"\"\"Senior IT Project Manager/Consultant Senior <span class=\\\"hl\\\">IT</span> <span class=\\\"hl\\\">Project</span> <span class=\\\"hl\\\">Manager</span>/Consultant Senior IT Project Manager/Consultant Chicago, IL Work Experience Senior IT Project Manager/Consultant Northern Trust Bank - Chicago, IL March 2015 to August 2015 Full PM responsibilities as indicated by Northern Trust's SDLC requirements, using waterfall methodology.  Managed multiple medium-sized IDM/IAM projects from Initiation through Design, including Program Management. Personal Leave September 2014 to February 2015 Senior IT Project Manager/Consultant Northern Trust Bank - Chicago, IL March 2012 to August 2014 Full PM responsibilities as indicated by Northern Trust's SDLC requirements, using waterfall methodology.  Managed a multi-year, multi-phased, large SDLC Project: Led project from Initiation to Project Closure as BA and PM.  IDM Rel 1.6 Web Cash Movement: development for auto-provisioning Web Cash Movement and all other web applications via Identity Management System (IDM/IAM) and Access Certification, delivering the functionality for Remove, Updates for Employees, Contractors and Clients, as well as Rehiring Terminated Employees and Contractors.  IDM Rel 1.4 Web Arch for UAT: enablement for auto-provisioning of Web Cash Movement apps via IDM to UAT Web Arch environment.  IDM Rel 1.3 Web Admin Alternative: UAT application auto-provisioning for Web Cash Movement via IDM, delivering initial functionality for Add Access to Production for Employees, Contractors and Clients.  Managed many small SDLC projects:  Manitou Patch Update: update to security system to current patch. Initiation.  IDM Rel 1.8 Employee Transfer. Initiation to Planning. Certifications/Licenses Certified Green Belt in Six Sigma Quality/Process Improvement Present Certified in ITIL Foundations, Operations and Service Delivery, ITIL V3 Present Certified Project Management Professional (PMP) PMI PMP #1345786 July 2010 to July 2016 Advanced training in project management, DePaul University, Chicago, IL Present Extensive corporate training in project management and PMO Present Additional Information HIGHLIGHTS of QUALIFICATIONS  ? Accomplished PMP certified IT Project Manager with 20+ years of project management experience at top tier global companies. ? IT professional with extensive background in Operations and Service Delivery, Business & Systems Development, and consulting. ? Highly skilled in adapting interpersonal skills with existing SMEs and support teams, project teams, and C-level management. ? Proven ability in achieving significant cost reductions, revenue growth, and efficiency improvements through the intelligent application of technology. ? Manages multiple IT projects simultaneously while meeting scope, deadlines and budgets. ? Strong track record of delivering application solutions (application development projects) to complex business problems in Identity Access Management (IAM), retail applications, IT infrastructure, and custom application software. ? Strategically focuses on high level goals while managing the details. ? Expert in leading decentralized teams of IT professionals to deliver excellence. ? Highly self-motivated Project Manager with strong team building skills.  Project Management Expertise  Developed and maintained productive working relationships with Stakeholders, Business Owners, Project Sponsors, Business Analysts, Solution Architects, Vendors, and Key Clients  Gained Stakeholder trust and brokered consensus throughout project  Acted as internal advocate for project  Provided insight for mission/business critical  Partnered between IT and Business to ensure internal teams are properly aligned throughout the project  Defined project charter, scope, objectives, deliverables and established measurement for benefits realization  Defined the project governance and provided regular status updates to steering committee in order to facilitate informed decisions  Gathered information required to estimate project cost, resources, and schedule  Developed and continually updated project plans and schedules  Managed the day-to-day activities of projects and staff to ensure project deliverables are on schedule and within cost performance.  Ensured the project deliverables meet users' requirements  Managed costs, schedule, scope control, change management and performance for the project  Developed a communication plan to convey project scope, goals, milestones, budget, risk, status, change requests and critical issues to the client and project team  Determined staffing requirements and developed budget requests for resources  Worked with Resource Managers in order to effectively align resources across projects  Negotiated changes in project resources as necessary to achieve objects and timelines  Created and managed resource calendars  Recruited and managed appropriate staffing resources  Drove all phases of IT Project Development life cycle including guiding the project team through requirements gathering, SIT and UAT planning and testing, and installation preparation and execution  Developed process designs to support business solutions and clarify business requirements  Approved invoices for payment  Identified the elements of risk in the project, utilizing SMEs, BA's, System Analysts, and other project personnel  Analyzed and prioritized project risks and assess potential impact to the client  Developed and maintained risk plans, processes and systems in order to mitigate risks and crate an action plan when they occur  Maintained issue lists and facilitated the resolution of issues throughout the project life cycle  Created and managed capital requests and revisions  Developed a detailed cost baseline from cost estimations  Refined project cost estimates and confirmed funding sources  Monitored and controlled the actual cost of the project versus the budget  Conducted in-depth root cause analysis of project budget discrepancies  Managed program release plan activities and communicated status to project team.  Performed project close financial processes  Adapted communication style to audience(s)  Wrote and presented status reports, Benefits Realization, Lessons Learned, Project Implementation Review and other project closure reports for and to management and steering committee  Implemented methodologies, processes, and tools developed by the PMO, exercising good judgment to tailor methodology to project  Owned SDLC process and internal processes, and trained and mentored staff and other PMs  Provided feedback regarding the continuous improvement of project standards and procedures  A driven, hands-on leader who does what it takes to get the job done.  COMPUTER SKILLS  Software: MS Office Suite, MS Outlook, MS Project, Visio Professional, SharePoint, SAP, XcelleNet, Siebel, Remedy, Planview Operating Systems: Windows (all), UNIX POS Systems: Retalix, Radiant, Wayne Nucleus, MSI, VeriFone, Gilbarco, Compris, SASI, NCR, IBM, ICL Programming: XML, SQL, Visual Basic, C++, JCL, HTML\",\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": (\n",
    "            \"You are an expert resume parser. \"\n",
    "            \"Extract structured information from resumes and return ONLY valid JSON. \"\n",
    "            \"Do not include explanations or extra text.\"\n",
    "        )\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"Resume:\\n{example_resume}\"\n",
    "    }\n",
    "]\n",
    "\n",
    "prompt = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True,\n",
    "    enable_thinking=False\n",
    ")\n",
    "\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=512,\n",
    "        do_sample=False,          # IMPORTANT\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "\n",
    "assistant_response = tokenizer.decode(\n",
    "    outputs[0][inputs[\"input_ids\"].shape[-1]:],\n",
    "    skip_special_tokens=True\n",
    ").strip()\n",
    "\n",
    "print(\"\\nGENERATED RESPONSE:\\n\", assistant_response)\n",
    "\n",
    "try:\n",
    "    parsed = json.loads(assistant_response)\n",
    "    print(\"\\n✓ Valid JSON\")\n",
    "    print(json.dumps(parsed, indent=2))\n",
    "except json.JSONDecodeError as e:\n",
    "    print(\"\\n⚠️ Invalid JSON:\", e)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}